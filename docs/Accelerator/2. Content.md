##User generated content##

In an e-commerce scenario we want to provide the flexibility for the users of our application to be able to upload custom content and have the application handle it in a way which will not significantly increase hosting costs or cause any end user performance degradation.

In this section we will explore ways in which we can upload and store images and have this content provided through an external source in the form of Azure blob storage. We will capture thumbnails and generate image metadata using Microsoft's Computer Vision APIs and cover ways in which to manage updated user content. Additionally, we will explore integration with the Azure Content Delivery Network (CDN) for providing scalability when serving content from our application.

For the purpose of demonstrating these scenarios, we will be extending the admin section of Parts Unlimited, in order to enable admins to create and modify product images used throughout the application.

###Creating and storing content###

####Storing content in Azure Storage alongside DocumentDB####

There are a few approaches to hosting content external to our application when considering the use of DocumentDB. One option is to store and have the raw content managed through the DocumentDB attachments feature. It is however, important to note that there is currently an attachment storage quota which can be viewed [here](https://azure.microsoft.com/en-us/documentation/articles/documentdb-limits/), and that integration with Azure CDN could prove difficult as a result of having to resolve the content reference URL through the attachment. Therefore the other recommended options is to make use of Azure blob storage. Doing so gives us the ability to better manage our own blobs, and serves as an alternative to the current DocumentDB storage quota limitations. In addition, using blob storage enables simplified integration with Azure CDN, and makes it possible to integrate with Azure Web Jobs and queues for the ability to take time consuming image manipulation tasks out of the regular application process, creating a more responsive end user experience. 

See [here](https://msdn.microsoft.com/en-nz/library/azure/dn782196.aspx) for an overview of the managed attachments features of DocumentDB.

Once an image has been stored inside blob storage, we can store its publicly available URL and other reference metadata inside DocumentDB as an attachment with externally hosted raw content as referenced by the "media" property of DocumentDB attachments. Later in this section, we will see an example of various product images stored alongside the product catalogue inside DocumentDB in this manner.

The following snippet provides an example of how the JSON construct of a DocumentDB attachment would look when referencing externally hosted content residing inside you Azure blob storage:

	{  
		"id":"image14e66102-9Oc4-4d2b-a423-faf221c71221",
		"contentType":"image/jpg",
		"media":"https://storagesample.blob.core.windows.net/mycontainer/myimage.jpg",
		"_rid":"rnYYAMVFUAUBAAAAAAAAAEC+LNM=",
		"_ts":1408056025,
		"_self":"dbs\/rnYYAA==\/colls\/rnYYAMVFUAU=\/docs\/rnYYAMVFUAUBAAAAAAAAAA==\/attachments\/rnYYAMVFUAUBAAAAAAAAAEC+LNM=",
		"_etag":"00002a00-0000-0000-0000-53ed3ad90000"
	}

Performing operations against DocumentDB attachements is similiar to performing operations against documents, however, they are performed against the "attachements" resource path under a particular document as opposed to the document or collection. To create an attachment for content hosted externally to DocumentDB, we simply need to post the attachment metadata for our particular document via the following request format:

	https://{databaseaccount}.documents.azure.com/dbs/{_rid-db}/colls/{_rid-col}/docs/{_rid-doc}/attachments
	
Where the `{databaseaccount}` is the name of the DocumentDB account created under your Azure subscription. The `{_rid-db}` is the ID of the database. The `{_rid-col}` is the ID of the collection the document is stored in. Finally, `{_rid-doc}`  is the document associated with the attachment.

The "Authorization" header will need to be set with with your signature token. Note that only the master key is allowed for these operations. More information can be found [here](https://msdn.microsoft.com/en-nz/library/azure/dn783368.aspx). The request body will need to contain the "Media" property, which will be the URL link to the externally hosted content, as well as the "contentType" property, set to the type of content.

The following is an example of a request to attach externally hosted content to a document:
	
	POST https://storagesample.documents.azure.com/dbs/hUwBcw==/colls/hUwBc+gfDX4=/docs/hUwBc+gfDX4DAAAAAAAAAA==/attachments HTTP/1.1
	x-ms-date: Thu, 14 Apr 2015 22:40:25 GMT
	authorization: type%3dmaster%26ver%3d1.0%26sig%3dza46lCo9nNr0%2fGMjryG8S%2b26ZsFABUYPlW3ebq26nDg%3d
	x-ms-version: 2015-04-08
	Content-Length: 88

	{"contentType":"image/jpg","media":"https://storagesample.blob.core.windows.net/mycontainer/myimage.jpg"}
    
Alternatively, the DocumentDB SDK provides the ability to create attachments as seen by the following example: (see the Parts Unlimited implementation [here](../../src/PartsUnlimitedWebsite/Repository/DocDbImageRepository.cs))

    private async Task AttachToDocumentDB(int productId, string imageUrl)
    {
        var productLink = _docDbConfiguration.BuildProductLink(productId);
        var client = _docDbConfiguration.BuildClient();

        await client.CreateAttachmentAsync(productLink, new { id = productId, contentType = "image/jpeg", media = imageUrl });
    }


####Manipulating images and extracting metadata####

When allowing for user generated images to be used within our application, it is important to account for potential raw content with a wide range of display ratios and file sizes. Raw content will need to be manipulated in order to serve images that fit the various design requirements of our application (e.g. image thumbnails, expanded images, and images optimised for display on various devices.). Storing and serving unnecessarily large images degrades the end user experience, and impacts hosting costs, as Azure services such as blob storage and CDN charge by file size.

There are various ways to account for these issues, and in this section we will explore the optimisation of user generated images through the use of Microsoft's Computer Vision APIs - a subset of the Project Oxford initiative, a collection of REST APIs and SDKs that enable developers to more easily add intelligent services into the applications that leverage Microsoft's natural data understanding capabilities. The Vision API enables us to manipulate our images and extract a wide range of information that includes Optical Character Recognition (OCR), identification of explicit content, image subject matter categorization, colour recognition, etc. interactive demoes of the Vision API capabilities can be see [here](https://www.projectoxford.ai/demo/vision#Analysis), with the API reference documentation found [here](https://dev.projectoxford.ai/docs/services/54ef139a49c3f70a50e79b7d/operations/550a323849c3f70b34ba2f8d)

 We will look at processing an image for optimised display, making use of Vision API's "smart crop" feature to generate image thumbnails that focus on the image subject matter. In addition, we will look at leveraging the Vision API to extract intelligent metadata from our image in the form of categorical image descriptions, and dominant foreground/background colours, which can be used to assist in searches.

See [here](https://www.projectoxford.ai/vision) for an overview of Microsoft's Computer Vision APIs.

The image source content can be provided in two ways - as a reference URL to an existing image, or by providing the actual raw image for processing. This gives us the flexibility to decide whether we would prefer to process our images pre, or post storing of the image to our Azure blob. Considerations as to which approach to take include whether we would prefer to store a copy of the original image in our blob, or whether we would prefer to take storage costs into consideration, and simply store the processed images which will get consumed by the application.

The format of our request URL to the API is as follows:
	
	https://api.projectoxford.ai/vision/v1/analyses[?visualFeatures]
	
Where `[?visualFeatures]` is an optional comma separated string which indicates which of the Vision API analysis features we would like to return. Ignoring the optional parameter will result in the full analysis result set being returned for our image. For optimal request times, we will opt to specify for only the color and categories analysis to be returned. A full list of options can be seen [here](https://dev.projectoxford.ai/docs/services/54ef139a49c3f70a50e79b7d/operations/550a323849c3f70b34ba2f8d)

Additionally we will need to set the request header for content type, with a value of "application/octet-stream" with our image file binary attached, and add a "Ocp-Apim-Subscription-Key" request header with the value set to our subscription key, which can be found [here](https://dev.projectoxford.ai/developer) after subscribing to Project Oxford as detailed in our setup section.

Our modified request URL now looks like the following:
	
	https://api.projectoxford.ai/vision/v1/analyses?visualFeatures=Color,Categories	

The response will be in the format of a JSON construct similar to below:

	{
		"categories": [
			{
			"name": "trans_car",
			"score": 0.98046875
			}
		],
		"requestId": "635e5da9-4971-402e-a84d-160c130c11ef",
		"metadata": {
			"width": 1500,
			"height": 1155,
			"format": "Jpeg"
		},
		"color": {
			"dominantColorForeground": "Grey",
			"dominantColorBackground": "White",
			"dominantColors": [
			"White"
			],
			"accentColor": "19A4B2",
			"isBWImg": false
		}
	}
    
Alternatively, the Project Oxford VisionAPI SDK can be used to accomplish the same result as below: (see the Parts Unlimited implementation [here](../../src/PartsUnlimitedWebsite/WebsiteConfiguration/VisionAPIConfiguration.cs))

    public async Task<AnalysisResult> AnalyseImage(string imageUrl)
    {
        var vision = new VisionServiceClient(Key);
        var visualFeatures = new[] { "Color", "Categories" };
        return await vision.AnalyzeImageAsync(imageUrl, visualFeatures);
    }

    public async Task<byte[]> GenerateThumbnail(string imageUrl)
    {
        var vision = new VisionServiceClient(Key);
        return await vision.GetThumbnailAsync(imageUrl, 295, 295, true);
    }
	
With image processing and metadata extraction now added to our application, we can consider improving website response times and improving the end user experience by removing the image processing and metadata extraction responsibility from the application. This can be done by making use of Azure WebJobs and Queues, handing off the Vision API image processing portion to a WebJob that awaits a messag placed in the Queue after the image has been uploaded by the user to our blob storage. This enables the user to upload an image, and then continue using the site, as opposed to being held up while the application processes the uploaded image. For more information on WebJobs and Queues, see the following guide [here](https://azure.microsoft.com/en-gb/documentation/articles/websites-dotnet-webjobs-sdk-storage-queues-how-to/). 

####Integrating Azure blob storage with Azure CDN####

With the addition of user generated content to our application, we need to consider the potential for scalability. A common way to achieve this is by moving content serving responsibility from our application onto a content delivery network. Azure CDN provides a simplified way to achieve this through integration with our application and the Azure blob storage where our content is hosted. Common considerations for the use of a CDN include situations where your application serves many links to static / semi-static content, is accessed by end users spread out globally, or you need to offload traffic from your web server. Ultimately, this results in improving the end user experience by shortening response times.

A detailed guide on serving CDN content from your blob storage can be found [here](https://azure.microsoft.com/en-us/documentation/articles/cdn-serve-content-from-cdn-in-your-web-application/)

There are some considerations in regards to managing content hosted through a CDN given that we are storing the content source URL alongside DocumentDB as an attachment. A decision needs to be made on when to resolve the URL of content that has been pushed to the CDN back to the "Media" property of our attachment, and whether this happens when the content is stored in the blob (storage time), or when the content is accessed through the application (read time). While storage time provides a simplified flow, as individual content can be resolved to the correct URL stored against the DocumentDB attachment the moment it is created in blob storage. Read time has the benefit of not needing to make updates to all items affected inside DocumentDB in the event that the CDN endpoint changes i.e. if we decide to later map the CDN to a [custom domain](https://azure.microsoft.com/en-us/documentation/articles/cdn-map-content-to-custom-domain/).

It is also important to consider the freshness of content in the CDN cache, as Azure CDN implements cache control with a default 7-day TTL (time to live). Therefore if content stored in blob storage is updated through the application, the change will not be reflected untill the cache expires and the CDN refreshes the content from the blob. There are some ways to work around this - The default expiration time can be shirtened by editing the properties of your blob container, but this will increase the traffic between the CDN and blob storage, and does not enable you to reflect immediate content changes in the application. Another option is to configure your CDN endpoint's query string caching behaviour to cache every unique URL. Doing so allows you to append a version number to your content URL, which will then be seen as a unique URL by the CDN, prompting it to collect the updated content from blob storage. More information on these methods of providing fresh content can be found [here](https://azure.microsoft.com/en-gb/documentation/articles/cdn-serve-content-from-cdn-in-your-web-application/#configure-the-cdn-cache-to-reflect-the-desired-content-update)

Another recently introduced method is the ability to purge stale content from the CDN. This will remove cached content from all edge nodes, and force the CDN to retrieve a fresh copy of the content without the need to change the URL by appending a version to it. It is important to note that this in currently only for CDn endpoints that have been created using the new [Azure Portal](https://portal.azure.com/), however all endpoints that have been created in the [previous version](https://manage.windowsazure.com/) of the portal will be migrated to the new portal in the beginning of 2016, at which point purge functionality will become available. A purge can be done in two ways, either through the portal by navigating to the endpoint and selectign the purge option, or via the CDN REST API, for which reference information can be found [here](https://msdn.microsoft.com/en-us/library/mt634451.aspx). Using this method, we can choose to purge all cached content from the CDN, or to granularly purge a specific path. This effectively enables the application to immediatly purge old content the moment it gets updated, ensuring users are always presented with the latest fresh content from the application.
